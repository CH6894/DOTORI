from fastapi import APIRouter, HTTPException, status
from datetime import datetime
import logging
from app.models.chat import ChatRequest, ChatResponse, ErrorResponse
from app.services.openai_service import openai_service

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/api", 
    tags=["ì±—ë´‡"],
    responses={
        404: {"description": "Not found"},
        500: {"model": ErrorResponse}
    }
)

_is_initialized = False

async def initialize_openai_service():
    """ì•± ì‹œì‘ì‹œ OpenAI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (PDF ë¡œë”© í¬í•¨)"""
    global _is_initialized
    if not _is_initialized:
        logger.info("ğŸ”„ OpenAI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        await openai_service.initialize()  # PDF ë¡œë”© + ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        _is_initialized = True
        logger.info("âœ… OpenAI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

@router.post(
    "/chat",
    response_model=ChatResponse,
    summary="ì±—ë´‡ ëŒ€í™”",
    description="ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ AI ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."
)
async def gen_answer(req: ChatRequest):

    try:
        # ì´ˆê¸°í™” í™•ì¸
        await initialize_openai_service()
        
        logger.info(f'ì…ë ¥: {req.message}')

        ai_response, session_id = await openai_service.generate_response(
            user_message=req.message,
            session_id=req.session_id,
            conversation_history=req.conversation_history
        )
        
        response = ChatResponse(
            response=ai_response,
            session_id=session_id,
            timestamp=datetime.now(),
            model_used="gpt-4o"
        )
        
        logger.info(f'ì‘ë‹µ ìƒì„± ì™„ë£Œ: {session_id}')
        return response
         
    except Exception as e:
        error_msg = f"ì±—ë´‡ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=error_msg
        )
    