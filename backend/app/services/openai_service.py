from typing import List, Tuple
import uuid
import logging
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain.memory import ConversationSummaryMemory
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

from app.config.settings import settings
from app.models.chat import ChatMessage, MessageRole

logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self):
        """
        RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        """
        try:
          
            self.llm = ChatOpenAI(
                model="gpt-3.5-turbo",
                openai_api_key=settings.OPENAI_API_KEY,
                temperature=0.2,
            )
            
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (pdfë¥¼ ë³´ê¸° ìœ„í•´ì„œ ê¼­ í•„ìš”í•œ ì½”ë“œ)
            # ë¬¸ìë¥¼ ìˆ«ìë¡œ(ë°±í„°í™”) ëŒë¦¬ëŠ” ì‘ì—… (=ì„ë² ë”©)
            self.embeddings = OpenAIEmbeddings(
                openai_api_key=settings.OPENAI_API_KEY
            )
            
            # ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
            self.session_memories = {}
            
            # PDF ë¬¸ì„œ ë¡œë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            self._setup_document_retrieval()
            
            logger.info("âœ… RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _setup_document_retrieval(self):
        """ë¬¸ì„œ ë¡œë”© ë° ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •"""
        try:
            # PDF ê²½ë¡œ
            pdf_path = "C:\\Users\\smhrd\\Documents\\mbti.pdf"
            
            # PDF ë¡œë”©
            logger.info(f"ğŸ“„ PDF ë¬¸ì„œ ë¡œë”© ì¤‘: {pdf_path}")
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=50,
                separators=["\n\n", "\n", ".", " ", ""]
            )
            texts = text_splitter.split_documents(documents)
            
            # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            logger.info("ğŸ” ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
            self.vectorstore = FAISS.from_documents(
                documents=texts,
                embedding=self.embeddings
            )
            self.retriever = self.vectorstore.as_retriever()
            
            # RetrievalQA ì²´ì¸ ìƒì„±
            self.chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.retriever,
                return_source_documents=True
            )
            
            logger.info(f"âœ… ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {len(texts)}ê°œ ì²­í¬ ìƒì„±")
            
        except Exception as e:
            logger.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
    
    def _get_or_create_memory(self, session_id: str):
        """ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ê´€ë¦¬ ê¸°ì–µí•˜ê¸°"""
        if session_id not in self.session_memories:
            self.session_memories[session_id] = ConversationSummaryMemory(
                llm=self.llm,
                max_token_limit=80,
                memory_key="chat_history",
                return_messages=True,
            )
            logger.info(f"ğŸ§  ìƒˆ ë©”ëª¨ë¦¬ ìƒì„±: {session_id}")
        
        return self.session_memories[session_id]
    
    async def generate_response(
        self, 
        user_message: str, 
        session_id: str = None,
    ) -> Tuple[str, str]:
        """RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        try:
            # ì„¸ì…˜ ID ì²˜ë¦¬
            if not session_id:
                session_id = str(uuid.uuid4())
            
            # ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸°
            memory = self._get_or_create_memory(session_id)
            
            logger.info(f"ğŸ¤– RAG ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: [{session_id}] {user_message[:50]}...")
            
            # RetrievalQA ì²´ì¸ìœ¼ë¡œ ë‹µë³€ ìƒì„±
            result = self.chain.invoke({"query": user_message})
            ai_response = result["result"]
            
            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
            memory.save_context(
                {"input": user_message},
                {"output": ai_response}
            )
            
            logger.info(f"âœ… RAG ì‘ë‹µ ìƒì„± ì™„ë£Œ: [{session_id}]")
            
            return ai_response, session_id
            
        except Exception as e:
            logger.error(f"âŒ RAG ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì§ˆë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def generate_general_response(
        self, 
        user_message: str, 
        conversation_history: List[ChatMessage] = None
    ) -> Tuple[str, str]:
        """ì¼ë°˜ ëŒ€í™”í˜• ì‘ë‹µ ìƒì„± (ë¬¸ì„œ ê²€ìƒ‰ ì—†ì´)"""
        try:
            # ë‹¤ëŒì¥ ìºë¦­í„° í”„ë¡¬í”„íŠ¸
            system_prompt = """ë‹¹ì‹ ì€ 'ë‹¤ëŒì´'ë¼ëŠ” ì´ë¦„ì˜ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹¤ëŒì¥ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •ì¤‘í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”. ğŸ¿ï¸"""
            
            # LangChain ë©”ì‹œì§€ íƒ€ì… import (ì—¬ê¸°ì„œë§Œ ì‚¬ìš©)
            from langchain.schema import HumanMessage, SystemMessage
            
            messages = [SystemMessage(content=system_prompt)]
            
            # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            if conversation_history:
                for msg in conversation_history[-5:]:
                    if msg.role == MessageRole.USER:
                        messages.append(HumanMessage(content=msg.content))
            
            # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
            messages.append(HumanMessage(content=user_message))
            
            # ì‘ë‹µ ìƒì„±
            response = await self.llm.ainvoke(messages)
            session_id = str(uuid.uuid4())
            
            return response.content, session_id
            
        except Exception as e:
            logger.error(f"âŒ ì¼ë°˜ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    async def health_check(self) -> bool:
        """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            self.chain.invoke({"query": "í…ŒìŠ¤íŠ¸"})
            return True
        except Exception as e:
            logger.error(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
            return False

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
openai_service = OpenAIService()