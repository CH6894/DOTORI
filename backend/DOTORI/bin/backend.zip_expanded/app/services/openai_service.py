from typing import List, Tuple
import uuid
import logging
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from openai import OpenAI
import json
from langchain.docstore.document import Document
from langchain.memory import ConversationSummaryMemory
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA

from app.config.settings import settings
from app.models.chat import ChatMessage

logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self):
        """ê¸°ë³¸ ì„œë¹„ìŠ¤ë§Œ ì´ˆê¸°í™” (PDF ë¡œë”©ì€ ë³„ë„ë¡œ)"""
        try:
            self.llm = ChatOpenAI(
                model="gpt-4o",
                openai_api_key=settings.OPENAI_API_KEY,
                temperature=0.2,
            )
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì¶”ê°€
            self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
            
            self.embeddings = OpenAIEmbeddings(
                openai_api_key=settings.OPENAI_API_KEY
            )
            
            self.session_memories = {}
            
            # âœ… ì „ì—­ ë³€ìˆ˜ë“¤ ì´ˆê¸°í™”ë§Œ (ì‹¤ì œ ë¡œë”©ì€ initialize()ì—ì„œ)
            self.vectorstore = None
            self.retriever = None
            self.chain = None
            self.is_initialized = False
            
            # í”„ë¡¬í”„íŠ¸ ìºì‹±
            self.system_prompt = None
            
            logger.info("âœ… ê¸°ë³¸ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def get_system_prompt(self):
        """íŒŒì¼ì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì½ì–´ì˜¤ê¸°"""
        if self.system_prompt is None:
            try:
                with open("prompts/system_prompt.txt", "r", encoding="utf-8") as f:
                    self.system_prompt = f.read()
                logger.info("âœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.system_prompt = ""
        return self.system_prompt

    async def initialize(self):
        if self.is_initialized:
            return
        try:
            # JSON ë°ì´í„°ê°€ ì´ë¯¸ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
            if self.vectorstore is None:
               json_path = "../data/figure_dummy_200.json"
                
            logger.info(f"ğŸ“„ JSON ë¬¸ì„œ ë¡œë”© ì¤‘: {json_path}")
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # ê° í•­ëª©ì„ Document ê°ì²´ë¡œ ë³€í™˜
                documents = []
                for item in data:
                    content = f"ID: {item['id']}, ì´ë¦„: {item['name']}, ì‹œë¦¬ì¦ˆ: {item['series']}, ìŠ¤íƒ€ì¼: {item['style']}, ê°€ê²©: {item['price']}ì›, ì¶œì‹œë…„ë„: {item['release_year']}, ìƒíƒœ: {item['condition']}, ì¬ê³ : {item['stock']}ê°œ"
                    doc = Document(
                        page_content=content, 
                        metadata=item
                    )
                    documents.append(doc)
                
                # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
                logger.info("ğŸ” ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
                self.vectorstore = FAISS.from_documents(
                    documents=documents,
                    embedding=self.embeddings
                )
                logger.info(f"âœ… JSON ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(documents)}ê°œ ìƒí’ˆ")
            
            # ë²¡í„°ìŠ¤í† ì–´ê°€ ì¤€ë¹„ë˜ë©´ ë‚˜ë¨¸ì§€ ì´ˆê¸°í™”
            if self.retriever is None:
                self.retriever = self.vectorstore.as_retriever(
                    search_kwargs={"k": 10}  # ìµœëŒ€ 10ê°œ ê²°ê³¼
                )
            
            if self.chain is None:
                # RetrievalQA ì²´ì¸ ìƒì„±
                self.chain = RetrievalQA.from_chain_type(
                    llm=self.llm,
                    chain_type="stuff",
                    retriever=self.retriever,
                    return_source_documents=True
                )
            
            self.is_initialized = True
            logger.info("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ JSON ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise
            
    def _get_or_create_memory(self, session_id: str):
        """ì„¸ì…˜ë³„ ë©”ëª¨ë¦¬ ê´€ë¦¬"""
        if session_id not in self.session_memories:
            self.session_memories[session_id] = ConversationSummaryMemory(
                llm=self.llm,
                max_token_limit=80,
                memory_key="chat_history",
                return_messages=True,
            )
            logger.info(f"ğŸ§  ìƒˆ ë©”ëª¨ë¦¬ ìƒì„±: {session_id}")
        
        return self.session_memories[session_id]
    
    async def generate_response(
        self, 
        user_message: str, 
        session_id: str = None,
        conversation_history: List[ChatMessage] = None
    ) -> Tuple[str, str]:
        """RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        
        # âœ… ìë™ ì´ˆê¸°í™” í™•ì¸
        if not self.is_initialized:
            await self.initialize()
        
        try:
            if not session_id:
                session_id = str(uuid.uuid4())
            
            memory = self._get_or_create_memory(session_id)
            
            logger.info(f"ğŸ¤– RAG ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: [{session_id}] {user_message[:50]}...")
            
            # ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
            system_prompt = self.get_system_prompt()
            
            # í”„ë¡¬í”„íŠ¸ì™€ ì§ˆë¬¸ ê²°í•©
            enhanced_query = f"{system_prompt}\n\nì‚¬ìš©ì ì§ˆë¬¸: {user_message}"
            
            # RetrievalQA ì²´ì¸ìœ¼ë¡œ ë‹µë³€ ìƒì„±
            result = self.chain.invoke({"query": enhanced_query})
            ai_response = result["result"]
            
            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
            memory.save_context(
                {"input": user_message},
                {"output": ai_response}
            )
            
            logger.info(f"âœ… RAG ì‘ë‹µ ìƒì„± ì™„ë£Œ: [{session_id}]")
            
            return ai_response, session_id
            
        except Exception as e:
            logger.error(f"âŒ RAG ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì§ˆë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

openai_service = OpenAIService()